{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import string\n",
    "import copy\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "import time\n",
    "from scipy.cluster.hierarchy import   linkage, single, complete, average, dendrogram\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmeans(data_to_cluster,k):\n",
    "    row_cluster_new = [0] * (len(data_to_cluster))\n",
    "    for iteration in range(50):\n",
    "        if iteration == 0:      \n",
    "            #Choose starting points randomly:\n",
    "            starting_points = data_to_cluster.ix[:,[2,3]].sample(n = k )     \n",
    "            row_cluster = [0]*len(data_to_cluster)       \n",
    "        else:     \n",
    "            row_cluster = list(row_cluster_new)\n",
    "        distance_to_cluster = [0]*len(data_to_cluster)     \n",
    "        columns = 2\n",
    "        for index, row in data_to_cluster.iterrows():    \n",
    "            distances = cdist(np.reshape(np.array(row[2:4]),(1,columns)) , np.array(starting_points))\n",
    "            row_cluster_new[index] = np.argmin(distances)\n",
    "            distance_to_cluster[index] = distances[0][np.argmin(distances)]\n",
    "        data_to_cluster['row_cluster'] = row_cluster_new            \n",
    "        data_to_cluster['distance_to_cluster'] = distance_to_cluster                \n",
    "        cluster_means = {}\n",
    "        for cluster in range(k):\n",
    "            current_cluster = data_to_cluster[data_to_cluster.row_cluster == cluster]            \n",
    "            cluster_means[cluster] = current_cluster.ix[:,[2,3]].mean()            \n",
    "        cluster_means = pd.DataFrame(cluster_means).transpose()            \n",
    "        del starting_points        \n",
    "        starting_points = cluster_means.copy(deep = True)        \n",
    "        if row_cluster == row_cluster_new:        \n",
    "            return data_to_cluster, row_cluster , starting_points, iteration            \n",
    "            #Now calculate the centroid of each cluster:\n",
    "    return data_to_cluster, row_cluster, starting_points, iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def within_cluster_sum_of_squares(clustered_data):\n",
    "    clustered_data['squared'] = clustered_data.distance_to_cluster * clustered_data.distance_to_cluster\n",
    "    return clustered_data.squared.sum()\n",
    "    \n",
    "def Silhouette(clustered_data , k):\n",
    "    clustered_data_covariates = clustered_data.ix[:,[2,3]]\n",
    "    distance_matrix = pdist(clustered_data_covariates)\n",
    "    distance_matrix = squareform(distance_matrix)   \n",
    "    del clustered_data_covariates   \n",
    "    distance_own_cluster_index = {}\n",
    "    distance_other_cluster_index = {}\n",
    "    for cluster in range(k):\n",
    "        distance_own_cluster_index[cluster] =  clustered_data[clustered_data['row_cluster'] == cluster].index.tolist()\n",
    "        distance_other_cluster_index[cluster] =  clustered_data[clustered_data['row_cluster'] != cluster].index.tolist()    \n",
    "    average_distance_own_cluster = [0]*len(clustered_data)\n",
    "    average_distance_other_cluster = [0]*len(clustered_data)    \n",
    "    for i in range(len(clustered_data)):\n",
    "        current_cluster = clustered_data.row_cluster.iloc[i]\n",
    "        average_distance_own_cluster[i] = np.mean(distance_matrix[i][distance_own_cluster_index[current_cluster]]) \n",
    "        average_distance_other_cluster[i] = np.mean(distance_matrix[i][distance_other_cluster_index[current_cluster]])       \n",
    "    average_distance_own_cluster = np.array(average_distance_own_cluster)\n",
    "    average_distance_other_cluster = np.array(average_distance_other_cluster)    \n",
    "    del clustered_data,distance_own_cluster_index,distance_other_cluster_index,distance_matrix    \n",
    "    S = average_distance_other_cluster - average_distance_own_cluster     \n",
    "    maximum = np.vstack( (average_distance_own_cluster,average_distance_other_cluster) ).transpose()   \n",
    "    maximum_index = np.argmax(maximum,axis=1)   \n",
    "    maximum = [maximum[i][maximum_index[i]] for i in range(len(maximum_index)) ]   \n",
    "    maximum = np.array(maximum)   \n",
    "    S = S / maximum  \n",
    "    return np.mean(S)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hclustering_create_clusters(z,clusters,level):\n",
    "    cluster_to_add = len(clusters) \n",
    "    for i in range(level):\n",
    "        group_1 = z[i][0]\n",
    "        group_2 = z[i][1]\n",
    "        clusters[clusters == group_1] = cluster_to_add\n",
    "        clusters[clusters == group_2] = cluster_to_add\n",
    "        cluster_to_add += 1           \n",
    "    unique_clusters = list(set(clusters))    \n",
    "    for i in range(len(unique_clusters)):\n",
    "        clusters[clusters == unique_clusters[i]] = i\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hclustering_single_linkage(data_to_cluster,k):\n",
    "    data_to_cluster_covariates = data_to_cluster.ix[:,[2,3]]\n",
    "    distance_matrix = pdist(data_to_cluster_covariates)\n",
    "    z = single(distance_matrix)\n",
    "    dendrogram(z)\n",
    "    plt.show()\n",
    "    clusters = np.array(range(len(data_to_cluster)))      \n",
    "    level = len(data_to_cluster) - k    \n",
    "    row_cluster = hclustering_create_clusters(z,clusters,level)   \n",
    "    data_to_cluster['row_cluster'] = row_cluster             \n",
    "    cluster_means = {}    \n",
    "    unique_clusters = list(set(row_cluster))    \n",
    "    for cluster in range(len(unique_clusters)):    \n",
    "        current_cluster = unique_clusters[cluster]        \n",
    "        current_subset = data_to_cluster[data_to_cluster.row_cluster == current_cluster]        \n",
    "        cluster_means[cluster] = current_subset.ix[:,[2,3]].mean()         \n",
    "    columns = 2\n",
    "    distance_to_cluster = [0]*len(data_to_cluster)       \n",
    "    for index, row in data_to_cluster.iterrows():    \n",
    "        current_cluster = row[4]\n",
    "        distance_to_cluster[index] = np.linalg.norm((np.array(row[2:4]))-(np.array(cluster_means[current_cluster])))                    \n",
    "    data_to_cluster['distance_to_cluster'] = distance_to_cluster\n",
    "    return data_to_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hclustering_complete_linkage(data_to_cluster,k):\n",
    "    data_to_cluster_covariates = data_to_cluster.ix[:,[2,3]]\n",
    "    distance_matrix = pdist(data_to_cluster_covariates)\n",
    "    z = complete(distance_matrix)\n",
    "    dendrogram(z)\n",
    "    plt.show()   \n",
    "    clusters = np.array(range(len(data_to_cluster)))       \n",
    "    level = len(data_to_cluster) - k    \n",
    "    row_cluster = hclustering_create_clusters(z,clusters,level)    \n",
    "    data_to_cluster['row_cluster'] = row_cluster             \n",
    "    cluster_means = {}    \n",
    "    unique_clusters = list(set(row_cluster))   \n",
    "    for cluster in range(len(unique_clusters)):    \n",
    "        current_cluster = unique_clusters[cluster]        \n",
    "        current_subset = data_to_cluster[data_to_cluster.row_cluster == current_cluster]       \n",
    "        cluster_means[cluster] = current_subset.ix[:,[2,3]].mean()\n",
    "    columns = 2\n",
    "    distance_to_cluster = [0]*len(data_to_cluster)       \n",
    "    for index, row in data_to_cluster.iterrows():          \n",
    "        current_cluster = row[4]\n",
    "        distance_to_cluster[index] = np.linalg.norm((np.array(row[2:4]))-(np.array(cluster_means[current_cluster])))                    \n",
    "    data_to_cluster['distance_to_cluster'] = distance_to_cluster\n",
    "    return data_to_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hclustering_average_linkage(data_to_cluster,k):\n",
    "    data_to_cluster_covariates = data_to_cluster.ix[:,[2,3]]\n",
    "    distance_matrix = pdist(data_to_cluster_covariates)\n",
    "    z = average(distance_matrix)\n",
    "    dendrogram(z)\n",
    "    plt.show() \n",
    "    clusters = np.array(range(len(data_to_cluster)))       \n",
    "    level = len(data_to_cluster) - k    \n",
    "    row_cluster = hclustering_create_clusters(z,clusters,level)    \n",
    "    data_to_cluster['row_cluster'] = row_cluster      \n",
    "    cluster_means = {}\n",
    "    unique_clusters = list(set(row_cluster))\n",
    "    for cluster in range(len(unique_clusters)):\n",
    "        current_cluster = unique_clusters[cluster]        \n",
    "        current_subset = data_to_cluster[data_to_cluster.row_cluster == current_cluster]        \n",
    "        cluster_means[cluster] = current_subset.ix[:,[2,3]].mean()         \n",
    "    columns = 2\n",
    "    distance_to_cluster = [0]*len(data_to_cluster)       \n",
    "    for index, row in data_to_cluster.iterrows():    \n",
    "        current_cluster = row[4]\n",
    "        distance_to_cluster[index] = np.linalg.norm((np.array(row[2:4]))-(np.array(cluster_means[current_cluster])))                    \n",
    "    data_to_cluster['distance_to_cluster'] = distance_to_cluster    \n",
    "    return data_to_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotWCSSD(clustered_data,range_of_k , method):\n",
    "    WCSSD = [0]*len(range_of_k)  \n",
    "    for i in range(len(range_of_k)):        \n",
    "        if method == 0:\n",
    "            z,a,b,loops = kmeans(clustered_data.copy(),range_of_k[i])  \n",
    "            del a,b,loops\n",
    "        elif method == 1:      \n",
    "            z = hclustering_single_linkage(clustered_data.copy(),range_of_k[i])  \n",
    "        elif method == 2:      \n",
    "            z = hclustering_complete_linkage(clustered_data.copy(),range_of_k[i])  \n",
    "        elif method == 3:      \n",
    "            z = hclustering_average_linkage(clustered_data.copy(),range_of_k[i])  \n",
    "        WCSSD[i] = within_cluster_sum_of_squares(z.copy())\n",
    "        del z        \n",
    "    return WCSSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nmi(clustered_data):\n",
    "\n",
    "    number_of_groups = len(clustered_data.row_cluster.unique())\n",
    "    number_of_classes = len(clustered_data.ix[:,[1]].unique())\n",
    "    n = len(clustered_data)\n",
    "    numerator = 0\n",
    "    denominator_1 = 0\n",
    "    denominator_2 = 0\n",
    "    for class_ in range(number_of_classes):\n",
    "        class_count = len(clustered_data[clustered_data.ix[:,[1]] == class_])\n",
    "        p_c = class_count / n\n",
    "        denominator_1 += p_c*(np.log(p_c))\n",
    "        for group in range(number_of_groups):\n",
    "            group_count = len(clustered_data[clustered_data.row_cluster == group])\n",
    "            p_g = group_count / n\n",
    "            if class_ == 0:\n",
    "                denominator_2 += p_g*(np.log(p_g))\n",
    "            p_c_g = len(clustered_data[ ( (clustered_data[clustered_data.ix[:,[1]] == class_]) & (clustered_data.row_cluster == group) ) ] )\n",
    "            numerator += p_c_g* ( np.log( (p_c_g / (p_c*p_g) ) ) )\n",
    "    nmi = numerator / (-denominator_1 - denominator_2)\n",
    "    return nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x = data_to_cluster.ix[:,[2,3]]\n",
    "print time.ctime()   \n",
    "digits_embedded = pd.read_csv('digits-embedding.csv' , header = None)\n",
    "\n",
    "k = 3\n",
    "data = digits_embedded.head(n=20)\n",
    "\n",
    "z,a,b,loops = kmeans(data.copy(),k)\n",
    "n = nmi(z)\n",
    "WCSSD = within_cluster_sum_of_squares(z.copy())\n",
    "  \n",
    "S = Silhouette(z , k)\n",
    "  \n",
    "#h = hclustering_single_linkage(data_to_cluster)\n",
    "#h = hclustering_complete_linkage(data_to_cluster)\n",
    "h = hclustering_single_linkage(data,k)\n",
    "WCSSD = within_cluster_sum_of_squares(h.copy())\n",
    "S = Silhouette(h , k)\n",
    "nmi = \n",
    "WCSSD_Graph = plotWCSSD(data.copy(),range(2,7) , 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
