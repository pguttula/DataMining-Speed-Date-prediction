{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-5cc2bbc7184b>, line 58)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-5cc2bbc7184b>\"\u001b[0;36m, line \u001b[0;32m58\u001b[0m\n\u001b[0;31m    if y_hat[i] != test_class[i]:\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "train = pd.read_csv('trainingSet.csv')\n",
    "test = pd.read_csv('testSet.csv')\n",
    "#lamb = 0.01\n",
    "\n",
    "def sigmoid(x):\n",
    "    return np.exp(x) / (1.0 - np.exp(x))\n",
    "\n",
    "def lr_weights(X,y,lam,eta,tol,steps,m):\n",
    "    n = len(y)\n",
    "    weights = np.zeros(m)\n",
    "    del_y = np.zeros(n)\n",
    "    y_hat = np.zeros(n)\n",
    "    grad_w = np.zeros(m)\n",
    "    for k in range(steps):\n",
    "        for i in range(n):\n",
    "            y_hat[i] = sigmoid(np.dot(weights.transpose(),X[i]))\n",
    "            if y_hat[i] >0.5:\n",
    "                y_hat[i] = 1  \n",
    "            else:\n",
    "                y_hat[i]=0\n",
    "            del_y[i] = (y[i] - y_hat[i])\n",
    "        X = np.asarray(X)\n",
    "        for j in range(m):\n",
    "            grad_w[j] = np.dot(del_y,X[:,j]) - lam*weights[j]\n",
    "            weights[j] += eta*grad_w[j]\n",
    "        if abs(eta*(np.linalg.norm(grad_w))) < tol:\n",
    "            break\n",
    "    return weights\n",
    "\n",
    "def lr(train,test):\n",
    "    eta = 0.01\n",
    "    lam = 0.01\n",
    "    tol = 0.000001\n",
    "    steps = 500\n",
    "    mistake = 0\n",
    "\n",
    "    train_class = [t[0] for t in train]\n",
    "    print train_class\n",
    "    train_set = [[1] + t[1] for t in train]\n",
    "    \n",
    "    m= len(train_set[0])\n",
    "    test_class = [t[0] for t in test]\n",
    "    test_set = [[1] + t[1] for t in test]\n",
    "               \n",
    "    w = lr_weights(train_set,train_class,lam,eta,tol,steps,m)\n",
    "    \n",
    "    y_hat = np.zeros(len(test_class))\n",
    "    for i in range(len(test_class)):\n",
    "        y_hat[i] = np.dot(w.transpose(),test_set[i])\n",
    "        y_hat[i] = int(round(y_hat[i]) #makes it 0 or 1, whichever is the closer int)\n",
    "        if y_hat[i] != test_class[i]:\n",
    "            mistake += 1\n",
    "    #print mistake\n",
    "    loss = mistake/float(len(test_class))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_svm(A,col,lamb,w_j): \n",
    "    A.predict_decision = A.predict_decision.astype(int)\n",
    "    A['temp'] = np.where((A['decision'] == 1 & A['predict_decision']) == 1, 0,A['decision']*A[col])\n",
    "    temparr = np.array(A['temp'])\n",
    "    temparr = lamb*w_j - temparr\n",
    "    gradient = np.sum(temparr)/len(A['decision'])\n",
    "    return gradient\n",
    "    \n",
    "def gradient_descent_svm(svm_train,lamb,w_old,stepsize):\n",
    "    gradient =[]\n",
    "    j=0\n",
    "    for col in svm_train.columns:\n",
    "        if col not in['decision','predict_decision']:\n",
    "            A = svm_train[[col,'decision','predict_decision']]\n",
    "            time1 = int(round(time.time() * 1000))\n",
    "            p = gradient_svm(A,col,lamb,w_old[j])\n",
    "            time2 = int(round(time.time() * 1000))\n",
    "            print \"Gradient_svn time: \", time2-time1\n",
    "            j+=1\n",
    "            gradient.append(p)\n",
    "    print gradient\n",
    "    gradient = np.array(gradient)\n",
    "    #print stepsize*gradient\n",
    "    w_new = w_old  - (stepsize*gradient)\n",
    "    return w_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
